{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import transpose\n",
    "from numpy.linalg import inv, det\n",
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "from numpy import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridgeFair(X, Y, k, d, _delta, T, _lambda):\n",
    "    \"\"\"\n",
    "    Simulates T rounds of ridgeFair.\n",
    "    \n",
    "    :param X: a 3-axis (T, k, d) ndarray of d-dimensional context vectors for each\n",
    "              time-step and arm\n",
    "    :param Y: a T x k ndarray of reward function output for each context vector\n",
    "    :param k: the number of arms\n",
    "    :param d: the number of features\n",
    "    :param _delta: confidence parameter\n",
    "    :param T: the number of iterations\n",
    "    :param _lambda:   \n",
    "    \"\"\"\n",
    "    picks = []\n",
    "    for t in range (T): # for t >= 1\n",
    "        for i in range(k): # for 1 <= i <= k\n",
    "            R = 1\n",
    "            intervals = []\n",
    "            try:\n",
    "                X_i = X[:t,i] # design matrix\n",
    "                Y_i = Y[:t,i] # same with Y\n",
    "                x_ti = X[t,i] # feature vector for arm i in round t\n",
    "\n",
    "                X_iT = transpose(X_i)\n",
    "                _idenD = np.identity(d)\n",
    "                V_it = X_iT.dot(X_i) + (_lambda*_idenD) # computing V_it as line 5\n",
    "\n",
    "                B_it = inv(V_it).dot(X_iT).dot(Y_i) # computing line 6\n",
    "                \n",
    "                y_ti = transpose(x_ti).dot(B_it) #computing line 7\n",
    "                \n",
    "                V_itI = inv(V_it) # inverse of V_it\n",
    "                _wti1 = sqrt(transpose(x_ti).dot(V_itI).dot(x_ti))\n",
    "                _wti2 = R * sqrt(d*log((1+(t/_lambda))/_delta)) + sqrt(_lambda)\n",
    "                w_ti = _wti1 * _wti2 # computing W_ti as line 8\n",
    "\n",
    "                intervals.append([y_ti - w_ti, y_ti + w_ti]) # line 9\n",
    "            except:\n",
    "                    print('Error in assigning interval value.')\n",
    "                    intervals = None\n",
    "                    break\n",
    "            if not intervals:\n",
    "                picks.append(np.random.randint(0,k))\n",
    "            else:\n",
    "                i_st = np.argmax(np.array(intervals)[:,1]) # line 10\n",
    "                chain = compute_chain(i_st, np.array(intervals), k) # line 11\n",
    "                picks.append(np.random.choice(chain)) # play uniformly random from chain\n",
    "                \n",
    "    best = [Y[i].max() for i in range(2, T)]\n",
    "    performance = [Y[t][picks[t-2]] for t in range(2, T)]\n",
    "    print('Cumulative Regret: {0}'.format(sum(best) - sum(performance)))\n",
    "    print('Final Regret: {0}'.format(best[-1] - performance[-1]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_chain(i_st, intervals, k):\n",
    "    # Sort intervals by decreasing order.\n",
    "    chain = [i_st]\n",
    "    ordering = np.argsort(intervals[:,1])[::-1]\n",
    "    intervals = intervals[ordering,:]\n",
    "    \n",
    "    lowest_in_chain = intervals[0][0]\n",
    "    for i in range(len(intervals)):\n",
    "        if intervals[i][1] >= lowest_in_chain:\n",
    "            chain.append(i)\n",
    "            lowest_in_chain = min(lowest_in_chain, intervals[i][0])\n",
    "        else:\n",
    "            return chain\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta(k, d, c):\n",
    "    \"\"\" \n",
    "    Generates the scaled down feature weights for a true model from the distribution\n",
    "    β ∼ U[0, c]^d.\n",
    "    \n",
    "    :param k: the number of arms \n",
    "    :param d: the number of features\n",
    "    :param c: the scale of the feature weights\n",
    "    \"\"\"\n",
    "    return np.random.uniform(0, c+1, size=(k, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Regret: 4636.449117347242\n",
      "Final Regret: 0.9403759272439949\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "c = 10\n",
    "d = 10\n",
    "T = 1000\n",
    "X = np.random.uniform(0, 1, size=(T, k, d)) # 3-axis ndarray\n",
    "B = beta(k, d, c)                           # true parameters. B[i]: params for arm i\n",
    "Y = np.array([np.diag(X[t].dot(transpose(B))) for t in range(T)])\n",
    "ridgeFair(X, Y, k, d, 0.05, T, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
